#!/usr/bin/env python3

from __future__ import print_function
import os
import argparse
import subprocess as sp
import sys
import urllib.parse
import json
import time
import tempfile
from datetime import datetime

class ES:
    def __init__(self, options):
        self.options = options
        self.commands = {
            # Help.
            "help":                   self.help,
            # Admin.
            "passwd":                 self.passwd,
            # Server EP info.
            "server":                 self.server,
            "port":                   self.port,
            "url":                    self.url,
            # Cluster info.
            "health":                 self.health,
            "status":                 self.status,
            "info":                   self.info,
            "shards":                 self.shards,
            "state":                  self.state,
            "aliases":                self.aliases,
            "plugins":                self.plugins,
            "tasks":                  self.tasks,
            "task":                   self.task,
            "cluster-stats":          self.cluster_stats,
            "cluster-settings":       self.cluster_settings,
            "merge-stats":            self.merge_stats,
            "thread-pool":            self.thread_pool,
            "load":                   self.load,
            "cpu-load":               self.cpu_load,
            "create-mappings":        self.create_mappings,
            "reindex-status":         self.reindex_status,
            "cancel-reindex":         self.cancel_reindex,
            "allocation":             self.allocation,
            "enable-allocation":      self.enable_allocation,
            "disable-allocation":     self.disable_allocation,
            "exclude-allocation":     self.exclude_allocation,
            "explain-allocation":     self.explain_allocation,
            "enable-rebalance":       self.enable_rebalance,
            "set-disk-allocation":    self.set_disk_allocation,
            "throttle":               self.throttle,
            "search-queue-size":      self.search_queue_size,
            "search-size":            self.search_size,
            "bulk-queue-size":        self.bulk_queue_size,
            "index-queue-size":       self.index_queue_size,
            "set-s3-repo":            self.set_s3_repo,
            "get-s3-repo":            self.get_s3_repo,
            "set-gcs-repo":           self.set_gcs_repo,
            "get-gcs-repo":           self.get_gcs_repo,
            "del-gcs-repo":           self.del_gcs_repo,
            "create-snapshot":        self.create_snapshot,
            "restore-snapshot":       self.restore_snapshot,
            "delete-snapshot":        self.delete_snapshot,
            "snapshot-overview":      self.snapshot_overview,
            "snapshot-info":          self.snapshot_info,
            "snapshot-status":        self.snapshot_status,
            "snapshot-progress":      self.snapshot_progress,
            "slm":                    self.slm,
            "create-slm":             self.create_slm,
            "delete-slm":             self.delete_slm,
            "execute-slm":            self.execute_slm,
            "init-cluster-recovery":  self.init_cluster_recovery,
            "cluster-recovery":       self.cluster_recovery,
            "index-recovery":         self.index_recovery,
            "explain-query":          self.explain_query,
            "analyze":                self.analyze,
            "license":                self.license,
            "watermark":              self.watermark,
            "template":               self.template,
            "create-template":        self.create_template,
            "delete-template":        self.delete_template,
            "script":                 self.script,
            "create-script":          self.create_script,
            "delete-script":          self.delete_script,
            "search-timeout":         self.search_timeout,
            "create-meta":            self.create_meta,
            "geoip":                  self.geoip,
            # Node commands.
            "nodes":                  self.nodes,
            "nodes-stats":            self.nodes_stats,
            "nodes-info":             self.nodes_info,
            "node":                   self.node,
            "os":                     self.os,
            "process":                self.process,
            "http":                   self.http,
            "breakers":               self.breakers,
            "jvm":                    self.jvm,
            "gc-risk":                self.gc_risk,
            "gc-bad":                 self.gc_bad,
            "hot-threads":            self.hot_threads,
            "segments-count":         self.segments_count,
            ## Index commands.
            "create-index":           self.create_index,
            "alias":                  self.alias,
            "alias-with-filter":      self.alias_with_filter,
            "unalias":                self.unalias,
            "stats":                  self.stats,
            "index-rate":             self.index_rate,
            "search-rate":            self.search_rate,
            "info":                   self.info,
            "mappings":               self.mappings,
            "settings":               self.settings,
            "cache-info":             self.cache_info,
            "query-cache":            self.query_cache,
            "request-cache":          self.request_cache,
            "enable-cache":           self.enable_cache,
            "clear-cache":            self.clear_cache,
            "open":                   self.open,
            "close":                  self.close,
            "optimize":               self.optimize,
            "replicate":              self.replicate,
            "refresh-interval":       self.refresh_interval,
            "flush_threshold_size":   self.flush_threshold_size,
            "durability":             self.durability,
            "sync-interval":          self.sync_interval,
            "reroute":                self.reroute,
            "nuke":                   self.nuke,
            "copy-info":              self.copy_info,
            "reindex":                self.reindex,
            "count":                  self.count,
            "recovery-stats":         self.recovery_stats,
            "refresh":                self.refresh,
            "flush":                  self.flush,
            "include":                self.include,
            "exclude":                self.exclude,
            "dump":                   self.dump,
            "move-shard":             self.move_shard,
            "cancel-move-shard":      self.cancel_move_shard,
            "move-primary-shard":     self.move_primary_shard,
            "random-shuffle":         self.random_shuffle,
            "max-result-window":      self.max_result_window,
            "read-mode":              self.read_mode,
            "write-mode":             self.write_mode,
            "exists":                 self.exists,
            "not-exists":             self.not_exists,
            "not-null":               self.not_null,
            "aggs":                   self.aggs,
            "read-only":              self.read_only,
            "enable-id-field-data":   self.enable_id_field_data,
            "version":                self.version,
            # Experiment commands.
            "must-match":             self.must_match,
            "should-match":           self.should_match,
            "filter":                 self.filter,
            "must-not":               self.must_not,
            "index":                  self.index,
            "index-json":             self.index_json,
            "index-dump":             self.index_dump,
            "stemmer-override":       self.stemmer_override,
            "synonyms":               self.synonyms,
            "get":                    self.get,
            "put":                    self.put,
            "post":                   self.post,
            "search":                 self.search,
            "update":                 self.update,
            "update-by-query":        self.update_by_query,
            "suggest":                self.suggest,
            "prefix-search":          self.prefix_search,
            "rank-feature":           self.rank_feature,
            # Unix-like commands.
            "ls":                     self.ls,
            "cat":                    self.cat,
            "rm":                     self.rm,
            "grep":                   self.grep,
            # Delete a doc
            "delete":                 self.delete,
            "delete-by-query":        self.delete_by_query,
            # LTR plugin
            # https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/building-features.html
            "ltr-featureset":         self.ltr_featureset,
            "create-ltr-featureset":  self.create_ltr_featureset,
            "delete-ltr-featureset":  self.delete_ltr_featureset,
            # https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/training-models.html
            "ltr-model":              self.ltr_model,
            "create-ltr-model":       self.create_ltr_model,
            "delete-ltr-model":       self.delete_ltr_model,
            # API keys management
            "api-keys":               self.api_keys,
            "create-api-key":         self.create_api_key,
            "delete-api-key":         self.delete_api_key,
            # Security
            "user":                   self.user,
            "create-user":            self.create_user,
            "create-superuser":       self.create_superuser,
            "delete-user":            self.delete_user,
            "role":                   self.role,
            "delete-role":            self.delete_role,
            "create-super-role":      self.create_super_role,
            "role-mapping":           self.role_mapping,
            "create-role-mapping":    self.create_role_mapping,
            "delete-role-mapping":    self.delete_role_mapping,
            "privilege":              self.privilege,
        }

    def __silent(self, on_off):
        res, self.options["silent"] = self.options["silent"], True
        return res

    def __url(self, argv = []):
        host, port = self.options["host"], self.options["port"]
        host_port = "%s:%s" % (host, port) if port != "" else host

        # Username and password when needed.
        username, pw = self.options["username"], self.options["password"]

        if username and pw:
            return "%s:%s@%s" % (username, pw, host_port)
        else:
            return "%s" % host_port

    def __argv(self, argv, i, default = ""):
        return argv[i] if len(argv) >= (i + 1) else default

    def __argvs(self, argv, i, default = []):
        return argv[i:] if len(argv) >= (i + 1) else default

    def __run(self, cmd, method = "GET", pipe = None, data = None):
        curl = "curl -sk -X%s" % method

        # ESv6 or greater requires content-type header.
        if not self.options["v2"] and method in [ "POST", "PUT", "GET", "DELETE" ]:
            curl += " -H 'Content-Type: application/json'"

        # Host, port and path.
        curl += " '%s/%s'" % (self.__url(), cmd)

        # Data
        if data:
            # When a single doc is too big, curl will fail due to CLI
            # length limitation.  In which case, we need to resort to
            # the external file method.
            if data and len(data) >= self.options["max_bulk_bytes"]:
                # es -v post stores-v4-old/_doc/200 < walmart-staging.json
                tmp_file = tempfile.NamedTemporaryFile(delete=False)
                tmp_file.write(data.encode())
                tmp_file.close()
                curl += " --data-binary @'%s'" % tmp_file.name
            else:
                # Escape \ with \\
                if data.find("\\") != -1:
                    data = data.replace("\\", "\\\\")

                # Escape ' with \'
                if data.find("'") != -1:
                    data = data.replace("'", "\\'")

                # Use $'' for bash string so that \' would work inside it.
                curl += " -d $'%s'" % data

        # Piping for specific info.
        if pipe:
            curl += " | %s" % pipe

        # Output the curl command if -v is specified.
        if self.options["verbose"]:
            print(curl, file=sys.stderr)

        # Run the curl command and capture the output.
        #res = sp.check_output(curl, shell=True).strip().decode("ascii", "ignore")
        res = sp.check_output(curl, shell=True).strip()
        if not self.options["silent"] and len(res) > 0:
            print(res.decode("utf-8", "ignore"))

        return res

    def run(self, command, argv):
        try:
            func = self.commands[command]
            func(argv)
        except KeyError as err:
            print("Missing %s" % err, file=sys.stderr)
            sys.exit(-1)
        except sp.CalledProcessError as err:
            print("Is ES running on %s?" % self.__url(), file=sys.stderr)
            sys.exit(-2)
        except Exception as err:
            raise(err)

        return self

    def help(self, argv = []):
        """help"""
        print("Some examples:")
        #for func in sorted(self.commands.values()):
        for func in self.commands.values():
            print("  es", func.__doc__)

    def passwd(self, argv = []):
        """passwd <username> <passwordd>"""
        username = self.__argv(argv, 0)
        password = self.__argv(argv, 1)

        settings = '''
        {
            "password": "%s"
        }
        ''' % password

        self.__run("_security/user/%s/_password" % username,
                   method = "POST", data = settings)

    def health(self, argv = []):
        """health [<green|yellow>] [<timeout>]"""
        if len(argv) == 0:
            self.__run("_cluster/health?pretty")
        else:
            wait = self.__argv(argv, 0, "green")
            timeout = self.__argv(argv, 1, "30s")
            self.__run("_cluster/health?pretty" +
                       "&wait_for_status=%s&timeout=%s" % (wait, timeout))

    def status(self, argv = []):
        """status"""
        self.__run("_cluster/health?pretty", pipe = "jq -r .status")

    def info(self, argv = []):
        """info [<index>]"""
        index = self.__argv(argv, 0)
        self.__run("%s?pretty" % index)

    def shards(self, argv = []):
        """shards [<index>] [-o <index|shard|state|docs|ip|node>]"""
        index = self.__argv(argv, 0)

        if index: index += "*"
        pipe = None if index else "grep -v '^\.'"

        sort = self.options["option"] or "index"

        fields = [
            "index",
            "shard",
            "prirep",
            "state",
            "docs",
            "store",
            "ip",
            "node",
            "unassigned.reason",
        ]
        self.__run("_cat/shards/%s?v&s=%s&h=%s" % \
                   (index, sort, ",".join(fields)), pipe = pipe)

    def server(self, argv = []):
        """server"""
        print(self.options["host"])

    def port(self, argv = []):
        """port"""
        print(self.options["port"])

    def url(self, argv = []):
        """url"""
        print(self.__url() + "/")

    def state(self, argv = []):
        """state"""
        self.__run("_cluster/state?pretty")

    def aliases(self, argv = []):
        """aliases"""
        if self.options["verbose"]:
            self.__run("_cat/aliases?v")
        else:
            self.__run("_cat/aliases?v", pipe="grep -v '^\.'")

    def plugins(self, argv = []):
        """plugins"""
        self.__run("_cat/plugins?v")

    def tasks(self, argv = []):
        """tasks"""
        self.__run("_tasks?pretty")

    def task(self, argv = []):
        """task <task_id>"""
        task_id = self.__argv(argv, 0)

        self.__run("_tasks/%s?pretty" % task_id)

    def cluster_stats(self, argv = []):
        """cluster-stats"""
        self.__run("_cluster/stats?pretty")

    def cluster_settings(self, argv = []):
        """cluster-settings"""
        self.__run("_cluster/settings?include_defaults&pretty")

    def merge_stats(self, argv = []):
        """merge-stats"""
        self.__run("_stats/merge?pretty")

    def thread_pool(self, argv = []):
        """thread-pool"""
        self.__run("_cat/thread_pool?v")

    def load(self, argv = []):
        """load (to be implemented)"""
        pass

    def cpu_load(self, argv = []):
        """cpu-load"""
        self.__run("_nodes/stats?pretty",
                   pipe = "jq -r '.nodes[] | [.name, .process.cpu.percent] | @tsv' | /usr/bin/sort -k2 -nr")

    def create_mappings(self, argv = []):
        """create-mappings [index] < mappings-file"""
        index = self.__argv(argv, 0, None)
        data = json.load(sys.stdin)

        for _index, value in data.items():
            # Create the index, its mappings and settings in one go.
            aliases  = value["aliases"] if "aliases" in value else {}
            settings = value["settings"]["index"]
            mappings = {
                "aliases": aliases,
                "settings": {
                    "analysis": settings["analysis"],
                    "index": {
                        "number_of_shards": settings["number_of_shards"],
                        "number_of_replicas": settings["number_of_replicas"]
                    }
                },
                "mappings": value["mappings"]
            }
            self.__run("%s" % index if index else _index,
                       method = "PUT", data = json.dumps(mappings))

    def reindex_status(self, argv = []):
        """reindex-status"""
        self.__run("_tasks?detailed=true&actions=*reindex&pretty")

    def cancel_reindex(self, argv = []):
        """cancel-reindex"""
        self.__run("_tasks/_cancel?actions=*reindex&pretty", "POST")

    def allocation(self, argv = []):
        """allocation [-o disk]"""
        disk = self.__argv(argv, 0)
        if self.options["option"] == "disk":
            self.__run("_cat/allocation?v&s=disk.percent,node")
        else:
            self.__run("_cat/allocation?v&s=node")

    def enable_allocation(self, argv = []):
        """enable-allocation <index>"""
        index = self.__argv(argv, 0)

        if index:
            settings = '''
            {
                "index": {
                    "routing.allocation.enable": "all"
                }
            }
            '''
            self.__run("%s/_settings?pretty" % index,
                       method = "PUT", data = settings)
        else:
            settings = '''
            {
                "transient": {
                    "cluster.routing.allocation.enable": "all"
                }
            }
            '''
            self.__run("_cluster/settings?pretty",
                       method = "PUT", data = settings)

    def disable_allocation(self, argv = []):
        """disable-allocation <index>"""
        index = self.__argv(argv, 0)

        if index:
            settings = '''
            {
                "index": {
                    "routing.allocation.enable": "none"
                }
            }
            '''
            self.__run("%s/_settings?pretty" % index,
                       method = "PUT", data = settings)
        else:
            settings = '''
                {
                    "transient": {
                        "cluster.routing.allocation.enable": "none"
                    }
                }
            '''
            self.__run("_cluster/settings?pretty",
                       method = "PUT", data = settings)

    # To exclude certain nodes to be used for shards allocation.
    def exclude_allocation(self, argv = []):
        """exclude-allocation <node-1>...<node-n>|none"""
        nodes = self.__argvs(argv, 0)

        settings = '''
        {
            "transient": {
                "cluster.routing.allocation.exclude._name": "%s"
            }
        }
        ''' % ",".join(nodes)
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    def explain_allocation(self, argv = []):
        """explain-allocation"""

        self.__run("_cluster/allocation/explain?pretty")

    def enable_rebalance(self, argv = []):
        """enable-rebalance <index> (to be implemented)"""

    def set_disk_allocation(self, argv = []):
        """set-disk-allocation <low> <high>"""
        low  = self.__argv(argv, 0, "85")
        high = self.__argv(argv, 1, "90")
        settings = '''
        {
            "transient": {
                "cluster.routing.allocation.disk.watermark.low": "%s%%",
                "cluster.routing.allocation.disk.watermark.high": "%s%%"
            }
        }
        ''' % (low, high)
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    def throttle(self, argv = []):
        """throttle <none|merge> [<size>](to be implemented)"""

    # Not working >= ES6 since those needs to be in the .yml config file.
    def search_queue_size(self, argv = []):
        """search-queue-size <int>"""
        size = self.__argv(argv, 0)
        settings = '''
            {
                 "transient": {
                     "threadpool.search.queue_size" : "%s"
                }
            }
        ''' % size
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    # Not working >= ES6 since those needs to be in the .yml config file.
    def search_size(self, argv = []):
        """search-size <int>"""
        size = self.__argv(argv, 0)
        settings = '''
            {
                 "transient": {
                     "threadpool.search.size" : "%s"
                }
            }
        ''' % size
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    def bulk_queue_size(self, argv = []):
        """bulk-queue-size <int> (to be implemented)"""

    def index_queue_size(self, argv = []):
        """index-queue-size <int> (to be implemented)"""

    def set_s3_repo(self, argv = []):
        """set-s3-repo <repo-name> <s3-bucket> <aws-region> <base-path>"""

    def get_s3_repo(self, argv = []):
        """get-s3-repo <repo-name>"""

    def set_gcs_repo(self, argv = []):
        """set-gcs-repo <repo-name> <gcs-bucket> <base-path>"""
        repo = self.__argv(argv, 0)
        bucket = self.__argv(argv, 1)
        base_path = self.__argv(argv, 2)
        settings = '''
        {
            "type": "gcs",
            "settings": {
              "bucket": "%s",
              "base_path": "%s",
              "compress": true,
              "max_snapshot_bytes_per_sec": "100mb",
              "max_restore_bytes_per_sec": "1024mb"
            }
        }
        ''' % (bucket, base_path)
        self.__run("_snapshot/%s?pretty" % repo,
                   method = "POST", data = settings)

    def get_gcs_repo(self, argv = []):
        """get-gcs-repo <repo-name>"""
        repo = self.__argv(argv, 0)
        self.__run("_snapshot/%s?pretty" % repo)

    def del_gcs_repo(self, argv = []):
        """del-gcs-repo <repo-name>"""
        repo = self.__argv(argv, 0)
        self.__run("_snapshot/%s?pretty" % repo, method="DELETE")

    def create_snapshot(self, argv = []):
        """create-snapshot  <repo-name> <snapshot-id> <indices>"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1, "_all")
        indices = self.__argvs(argv, 2)

        if not indices:
            # Create snapshots for all indices.
            self.__run("_snapshot/%s/%s?pretty" % (repo, snapshot_id),
                       method = "POST")
        else:
            # Restore snapshots for the given indices.
            settings = '''
            {
                "indices": "%s",
                "include_global_state": false
            }
            ''' % ",".join(indices)
            self.__run("_snapshot/%s/%s?pretty" % (repo, snapshot_id),
                       method = "POST", data = settings)

    def restore_snapshot(self, argv = []):
        """restore-snapshot <repo-name> <snapshot-id> <indices>"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1, "_all")
        indices = self.__argvs(argv, 2)

        if not indices:
            # Restore snapshots for all indices.
            self.__run("_snapshot/%s/%s/_restore?pretty" % (repo, snapshot_id),
                       method =  "POST")
        else:
            # Restore snapshots for the given indices.
            settings = '''
            {
                "indices": "%s",
                "include_global_state": false,
                "index_settings": {
                    "index.number_of_replicas": 0,
                    "index.routing.allocation.enable": "all"
                },
                "ignore_index_settings": [
                    "index.routing.allocation.include.tag"
                ]
            }
            ''' % ",".join(indices)
            self.__run("_snapshot/%s/%s/_restore?pretty" % (repo, snapshot_id),
                       method = "POST", data = settings)

    def delete_snapshot(self, argv = []):
        """delete-snapshot <repo-name> <snapshot-id>"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1)
        if len(snapshot_id) == 0:
            print("Please provide a snapshot_id!")
            return

        self.__run("_snapshot/%s/%s?pretty" % (repo, snapshot_id),
                   method = "DELETE")

    def snapshot_overview(self, argv = []):
        """snapshot-overview <repo-name>"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1, "_all")
        self.__run("_snapshot/%s/%s?pretty" % (repo, snapshot_id), pipe="jq -r '.snapshots[]|[.snapshot,.state]|@tsv'")

    def snapshot_info(self, argv = []):
        """snapshot-info <repo-name> <snapshot-id>"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1, "_all")
        if repo:
            self.__run("_snapshot/%s/%s?pretty" % (repo, snapshot_id))
        else:
            self.__run("_snapshot/%s?pretty" % snapshot_id)

    def snapshot_status(self, argv = []):
        """snapshot-status <repo-name>"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1, "_all")
        self.__run("_snapshot/%s/%s/_status?pretty" % (repo, snapshot_id))

    def snapshot_progress(self, argv = []):
        """snapshot-progress <repo-name> [<snapshot_id>] [<incremental>]"""
        repo = self.__argv(argv, 0)
        snapshot_id = self.__argv(argv, 1, "_all")
        incremental = self.__argv(argv, 2, "false")

        if incremental == "true":
            self.__run("_snapshot/%s/%s/_status?pretty" % (repo, snapshot_id), pipe="jq '.snapshots[].stats|.incremental.size_in_bytes/.total.size_in_bytes'")
        else:
            self.__run("_snapshot/%s/%s/_status?pretty" % (repo, snapshot_id), pipe="jq '.snapshots[].stats|.processed.size_in_bytes/.total.size_in_bytes'")

    def slm(self, argv = []):
        """slm <policy-name>"""
        name = self.__argv(argv, 0)
        self.__run("_slm/policy/%s" % name, pipe = "jq")

    def create_slm(self, argv = []):
        """create-slm <policy-name>"""
        name = self.__argv(argv, 0)
        self.__run("_slm/policy/%s" % name, method = "PUT", data = "@-")

    def delete_slm(self, argv = []):
        """delete-slm <policy-name>"""
        name = self.__argv(argv, 0)
        self.__run("_slm/policy/%s" % name, method = "DELETE")

    def execute_slm(self, argv = []):
        """execute-slm <policy-name>"""
        name = self.__argv(argv, 0)
        self.__run("_slm/policy/%s/_execute" % name, method = "POST")

    def init_cluster_recovery(self, argv = []):
        """init-cluster-recovery <num>"""
        num = self.__argv(argv, 0)
        setting = '''
        {
            "transient": {
                "cluster": {
                    "routing": {
                        "allocation": {
                            "node_initial_primaries_recoveries": "%s"
                        }
                    }
                }
            }
        }
        ''' % num
        self.__run("_cluster/settings?pretty", method = "PUT", data = setting)

    def cluster_recovery(self, argv = []):
        """cluster-recovery <num>"""
        num = self.__argv(argv, 0)
        setting = '''
        {
            "transient": {
                "cluster": {
                    "routing": {
                        "allocation": {
                            "node_concurrent_recoveries": "%s"
                        }
                    }
                }
            }
        }
        ''' % num
        self.__run("_cluster/settings?pretty", method = "PUT", data = setting)

    # Not working for new ES.
    def index_recovery(self, argv = []):
        """index-recovery <num>"""
        num = self.__argv(argv, 0)
        settings = '''
        {
            "transient": {
                "indices": {
                    "recovery": {
                        "concurrent_streams": "%s"
                    }
                }
            }
        }
        ''' % num
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    def explain_query(self, argv = []):
        """explain-query <index>"""
        index = self.__argv(argv, 0)
        self.__run("%s/_validate/query?explain&pretty" % index, data = "@-")

    def analyze(self, argv = []):
        """analyze <index> <analyzer> <text>"""
        index    = self.__argv(argv, 0)
        analyzer = self.__argv(argv, 1, "standard")
        text     = self.__argv(argv, 2)

        data = '''
        {
          "analyzer": "%s",
          "text": "%s"
        }
        ''' % (analyzer, text)
        self.__run("%s/_analyze?pretty" % index, method = "POST", data = data)

    def license(self, argv = []):
        """license"""
        self.__run("_license")

    def watermark(self, argv = []):
        """watermark <low> <high>"""
        low = self.__argv(argv, 0)
        high = self.__argv(argv, 1)
        settings = '''
        {
            "transient": {
                "cluster.routing.allocation.disk.watermark.low": "%s",
                "cluster.routing.allocation.disk.watermark.high": "%s"
            }
        }
        ''' % (low, high)
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    def template(self, argv = []):
        """template <template-name>"""
        template_name = self.__argv(argv, 0)
        self.__run("_template/%s" % template_name, pipe = "jq")

    def create_template(self, argv = []):
        """create-template <template-name> < file"""
        template_name = self.__argv(argv, 0)
        self.__run("_template/%s" % template_name, method = "PUT", data = "@-")

    def delete_template(self, argv = []):
        """delete-template <template-name>"""
        template_name = self.__argv(argv, 0)
        self.__run("_template/%s" % template_name, method = "DELETE")

    def script(self, argv = []):
        """script <script-name>"""
        script_name = self.__argv(argv, 0)
        self.__run("_scripts/%s" % script_name, pipe = "jq")

    def create_script(self, argv = []):
        """create-script <script-name> < file"""
        script_name = self.__argv(argv, 0)
        self.__run("_scripts/%s" % script_name, method = "PUT", data = "@-")

    def delete_script(self, argv = []):
        """delete-script <script-name>"""
        script_name = self.__argv(argv, 0)
        self.__run("_scripts/%s" % script_name, method = "DELETE")

    def search_timeout(self, argv = []):
        """search-timeout <timeout>"""
        timeout = self.__argv(argv, 0)
        settings = '''
        {
            "transient": {
                "search.default_search_timeout": "%s"
            }
        }
        ''' % timeout
        self.__run("_cluster/settings?pretty", method = "PUT", data = settings)

    def create_meta(self, argv = []):
        """create-meta index json-str"""
        index = self.__argv(argv, 0)
        meta = self.__argv(argv, 1)
        _meta = {
            "_meta": json.loads(meta)
        }
        self.__run("%s/_mapping" % index, method = "PUT",
                   data = json.dumps(_meta))

    def geoip(self, argv=[]):
        """geoip [<enable>|<disable>]"""
        toggle = self.__argv(argv, 0)

        if toggle == "enable":
            enable = True
        elif toggle == "disable":
            enable = False

        settings = json.dumps({
            "persistent": {
                "ingest.geoip.downloader.enabled": enable
            }
        })

        self.__run("_cluster/settings?pretty", "PUT", data=settings)

    def nodes(self, argv = []):
        """nodes [-o [heap|ram|cpu]]"""
        if self.options["option"] == "heap":
            self.__run("_cat/nodes?v&s=heapPercent")
        elif self.options["option"] == "ram":
            self.__run("_cat/nodes?v&s=ramPercent")
        elif self.options["option"] == "cpu":
            self.__run("_cat/nodes?v&s=cpu")
        else:
            self.__run("_cat/nodes?v&s=name")

    def nodes_stats(self, argv = [], pipe = None):
        """nodes-stats"""
        node = self.__argv(argv, 0)
        self.__run("_nodes/%s/stats?pretty" % node, pipe = pipe)

    def nodes_info(self, argv = []):
        """nodes-info"""
        self.__run("_nodes?pretty")

    def node(self, argv = []):
        """node [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__run("_nodes/%s?pretty" % node)

    def __nodes_stats_helper (self, node, field):
        pipe = "jq '.nodes[]|{name:.name, %s:.%s}'" % (field, field)
        self.nodes_stats(node, pipe = pipe)

    def os(self, argv = []):
        """os [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__nodes_stats_helper(node, "os")

    def process(self, argv = []):
        """process [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__nodes_stats_helper(node, "process")

    def http(self, argv = []):
        """http [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__nodes_stats_helper(node, "http")

    def breakers(self, argv = []):
        """breakers [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__nodes_stats_helper(node, "breakers")

    def jvm(self, argv = []):
        """jvm [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__nodes_stats_helper(node, "jvm")

    # https://www.elastic.co/guide/en/elasticsearch/guide/current/_monitoring_individual_nodes.html
    def __gc_helper (self, node, percent):
        pipe = \
            "jq -r '.nodes[]|[.host, .jvm.mem.heap_used_percent > %s] | @tsv'| sort -k2r -k1" % percent
        self.nodes_stats(node, pipe = pipe)

    def gc_risk(self, argv = []):
        """gc-risk [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__gc_helper(node, 75)

    def gc_bad(self, argv = []):
        """gc-bad [<node_name>]"""
        node = self.__argv(argv, 0)
        self.__gc_helper(node, 90)

    def hot_threads(self, argv = []):
        """hot-threads"""
        node = self.__argv(argv, 0)
        size = self.__argv(argv, 1, 3)
        self.__run("_nodes/%s/hot_threads?threads=%s" % (node, size))

    def segments_count(self, argv = []):
        """segments-count"""
        pipe = "jq -r '.nodes[]|[.name,.indices.segments.count]|@tsv'|sort"
        self.nodes_stats("", pipe = pipe)

    def create_index(self, argv = []):
        """create-index <index_name>"""
        index = self.__argv(argv, 0)
        self.__run("%s" % index, "PUT")

    def alias(self, argv = []):
        """alias <index_name> <alias1[,alias2]> [<old-index>]"""
        index = self.__argv(argv, 0, None)
        alias = self.__argv(argv, 1)
        old_index = self.__argv(argv, 2, None)

        if index == "-" or index == None:
            self.__run("_aliases", "POST", data="@-")
        else:
            aliases = alias.split(",")
            cmd = {}
            cmd["actions"] = [{"add": {"index": index, "alias": a}} for a in aliases]

            if old_index:
                cmd["actions"] += [{"remove": { "index": old_index, "alias": a }} for a in aliases]

            self.__run("_aliases", "POST", data=json.dumps(cmd));

    def alias_with_filter(self, argv = []):
        """alias-with-filter <index_name> <alias1[,alias2]> <filter|must_not> <key> <value>"""
        index = self.__argv(argv, 0)
        aliases = self.__argv(argv, 1)
        filter_or_must_not = self.__argv(argv, 2)
        key = self.__argv(argv, 3)
        value = self.__argv(argv, 4)

        cmd = {
            "actions": [{
                "add": {
                    "index": index,
                    "alias": alias,
                    "filter": {
                        "bool": {
                            filter_or_must_not: [{
                                "terms": {
                                    key: [ value ]
                                }
                            }]
                        }
                    }
                }
            } for alias in aliases.split(",")]
        }

        self.__run("_aliases", "POST", data=json.dumps(cmd));

    def unalias(self, argv = []):
        """unalias <index_name> <alias>"""
        index = self.__argv(argv, 0)
        new_index = self.__argv(argv, 1)
        self.__run("%s/_alias/%s?pretty" % (index, new_index), "DELETE")
        '''
        cmd = """
        {
            "actions": [
                { "remove": { "index": "%s", "alias": "%s" } }
            ]
        }
        """ % (index, new_index)
        self.__run("_aliases", "POST", data = cmd);
        '''

    def stats(self, argv = []):
        """stats [<index>]"""
        index = self.__argv(argv, 0)
        self.__run("%s/_stats?pretty" % index)

    def index_rate(self, argv = []):
        """index-rate [<index>] [interval] [window_size]"""
        index = self.__argv(argv, 0)
        interval = int(self.__argv(argv, 1, 5))
        window_size = int(self.__argv(argv, 2, 20))

        self.__silent(True)

        window = []
        now, now_time = 0, 0
        prev, prev_time = 0, 0

        while True:
            stats = json.loads(self.__run("_stats?filter_path=indices.%s.total.indexing.index_total" % index))
            now = stats["indices"][index]["total"]["indexing"]["index_total"]
            now_time = datetime.now()

            if prev == 0:
                prev, prev_time = now, now_time
                continue

            rate = (now - prev) / (now_time - prev_time).total_seconds()
            window.append(rate)
            if len(window) > window_size: window = window[-window_size:]
            print("%.02f" % (sum(window) / len(window)))

            time.sleep(interval)

    def search_rate(self, argv = []):
        """search-rate [<index>] [interval] [window_size]"""
        index = self.__argv(argv, 0)
        interval = int(self.__argv(argv, 1, 5))
        window_size = int(self.__argv(argv, 2, 20))

        self.__silent(True)

        window = []
        now, now_time = 0, 0
        prev, prev_time = 0, 0

        while True:
            stats = json.loads(self.__run("_stats?filter_path=indices.%s.total.search.query_total" % index))
            now = stats["indices"][index]["total"]["search"]["query_total"]
            now_time = datetime.now()

            if prev == 0:
                prev, prev_time = now, now_time
                continue

            rate = (now - prev) / (now_time - prev_time).total_seconds()
            window.append(rate)
            if len(window) > window_size: window = window[-window_size:]
            print("%.02f" % (sum(window) / len(window)))

            time.sleep(interval)

    def info(self, argv = []):
        """info [<index>]"""
        index = self.__argv(argv, 0)
        self.__run("%s?pretty" % index)

    def mappings(self, argv = []):
        """mappings [<index>]"""
        index = self.__argv(argv, 0)
        self.__run("%s/_mappings?pretty" % index)

    def settings(self, argv = []):
        """settings [<index>]"""
        index = self.__argv(argv, 0)
        self.__run("%s/_settings?pretty" % index)

    def cache_info(self, argv = []):
        """cache-info"""
        self.__run("_cat/nodes?v&h=id,queryCacheMemory,queryCacheEvictions,requestCacheMemory,requestCacheHitCount,requestCacheMissCount,flushTotal,flushTotalTime")

    def query_cache(self, argv = []):
        """query-cache"""
        human = "true" if self.options["human"] else "false"
        self.__run("_stats/query_cache?human=%s" % human)

    def request_cache(self, argv = []):
        """request-cache"""
        human = "true" if self.options["human"] else "false"
        self.__run("_stats/request_cache?human=%s" % human)

    def enable_cache(self, argv = []):
        """enable-cache [<index>]"""
        index = self.__argv(argv, 0)
        settings = { "index.requests.cache.enable": True }
        self.__run("%s/_settings?pretty" % index,
                   method="PUT", data=json.dumps(settings))

    def clear_cache(self, argv = []):
        """clear-cache [<index>]"""
        index = self.__argv(argv, 0)
        self.__run("%s/_cache/clear?pretty" % index, "POST")

    def open(self, argv = []):
        """open <index>"""
        index = self.__argv(argv, 0)
        self.__run("%s/_open?pretty" % index, "POST")

    def close(self, argv = []):
        """close <index>"""
        index = self.__argv(argv, 0)
        self.__run("%s/_close?pretty" % index, "POST")

    # XXX
    def optimize(self, argv = []):
        """optimize <index> [num]"""
        index = self.__argv(argv, 0)
        num = self.__argv(argv, 1, 1)
        self.__run("%s/_forcemerge?max_num_segments=%s&pretty" % (index, num),
                   "POST")

    def replicate(self, argv = []):
        """replicate <index> num"""
        index = self.__argv(argv, 0)
        num   = self.__argv(argv, 1)
        settings = """
        {
            "settings": {
                "index": {
                    "number_of_replicas": "%s"
                }

            }
        }""" % num
        self.__run("%s/_settings?pretty" % index, "PUT", data = settings)

    def refresh_interval(self, argv = []):
        """refresh-interval <index> num"""
        index = self.__argv(argv, 0)
        interval = self.__argv(argv, 1)
        settings = """
        {
            "settings": {
                "index": {
                    "refresh_interval": "%s"
                }

            }
        }""" % interval
        self.__run("%s/_settings?pretty" % index, "PUT", data = settings)

    def flush_threshold_size(self, argv = []):
        """flush_threshold_size <index> num"""

    def durability(self, argv = []):
        """durability <index> [async|request]"""
        index = self.__argv(argv, 0)
        mode  = self.__argv(argv, 1)
        settings = """
        {
            "settings": {
                "index": {
                    "translog.durability": "%s"
                }

            }
        }""" % mode
        self.__run("%s/_settings" % index, "PUT", data = settings)

    def sync_interval(self, argv = []):
        """sync-interval <index> num"""

    def reroute(self, argv = []):
        """reroute <index> <node>"""
        index = self.__argv(argv, 0)
        node  = self.__argv(argv, 1)
        settings = """
        {
            "commands": [
                {
                    "allocate": {
                        "index": "%s",
                        "shard": 0,
                        "node": "%s",
                        "allow_primary": 1
                    }
                }
            ]
        }""" % (index, node)

        # Not working yet.
        #self.__run("_cluster/reroute?pretty", "POST", data = settings)

        # XXX: Temp fix.
        self.__run("_cluster/reroute?retry_failed=true&pretty", "POST")

    def nuke(self, argv = []):
        """nuke <index> <type>"""
        index = self.__argv(argv, 0)
        type = self.__argv(argv, 1)
        self.__run("%s/%s/_delete_by_query?pretty" % (index, type), "POST",
                   data = '{ "query": { "match_all": {} } }')

    def copy_info(self, argv = []):
        """copy-info <old_index> <new_index> <type>"""

    def reindex(self, argv = []):
        """reindex <old_index> <new_index>"""
        old_index = self.__argv(argv, 0)
        new_index = self.__argv(argv, 1)
        reindex_cmd = """
        {
            "source": {
                "index": "%s",
                "size": 5000
            },
            "dest": {
                "index": "%s",
                "version_type": "external"
            },
            "script": {
                "inline": "ctx._source.remove(\\"_id\\")"
            }
        }
        """ % (old_index, new_index)
        self.__run("_reindex?wait_for_completion=false&pretty",
                   "POST", data = reindex_cmd)

    def count(self, argv = []):
        """count <index> <k|m|g>"""
        index = self.__argv(argv, 0)
        unit  = self.__argv(argv, 1, "b")
        ep    = "%s/_count" % index
        if unit in ["k", "K"]:
            self.__run(ep, pipe = "jq -r '.count/1000'")
        elif unit in ["m", "M"]:
            self.__run(ep, pipe = "jq -r '.count/1000000'")
        elif unit in ["g", "G"]:
            self.__run(ep, pipe = "jq -r '.count/1000000000'")
        else:
            self.__run("%s/_count" % index, pipe = "jq -r '.count'")

    def recovery_stats(self, argv = []):
        """recovery-stats <index>"""
        index = self.__argv(argv, 0)
        self.__run("_cat/recovery/%s?h=i,s,t,st,snode,shost,tnode,thost,f,fp,b,bp" % index)

    def refresh(self, argv = []):
        """refresh <index>"""
        index = self.__argv(argv, 0)
        if index:
            self.__run("%s/_refresh?pretty" % index)
        else:
            self.__run("_refresh?pretty")

    def flush(self, argv = []):
        """flush <index>"""
        index = self.__argv(argv, 0)
        if index:
            self.__run("%s/_flush?pretty" % index)
        else:
            self.__run("_flush?pretty")

    def include(self, argv = []):
        """include <index> <tag> <bin>"""

    def exclude(self, argv = []):
        """exclude <index> <tag> <bin>"""

    def dump(self, argv = []):
        """dump <index>"""
        index = self.__argv(argv, 0)
        size  = self.options["size"]
        query = """
        {
            "query": {
                "match_all": {}
            }
        }
        """

        silent = self.__silent(True)

        # Get the 1st batch.
        res = self.__run("%s/_search?pretty&size=%s&scroll=1m" % (index, size),
                         method = "POST", data = query)
        data = json.loads(res)

        # Return if no hits.
        hits = data["hits"]["hits"]
        if not hits:
            self.__silent(silent)
            return

        # Get the scroll_id.
        scroll_id = data["_scroll_id"]

        # Output the 1st batch of the results.
        for hit in hits:
            del(hit["_score"])
            print(json.dumps(hit))

        # Construct for the next batches.
        query = """
        {
            "scroll": "1m",
            "scroll_id": "%s"
        }
        """ % scroll_id

        while True:
            # Get the next batch.
            res = self.__run("_search/scroll?pretty",
                             method = "POST", data = query)
            data = json.loads(res)

            # Break if no hits.
            hits = data["hits"]["hits"]
            if not hits: break

            # Output the 2nd batch of the results.
            for hit in hits:
                del(hit["_score"])
                print(json.dumps(hit))

        self.__silent(silent)

    def move_shard(self, argv = []):
        """move-shard <index> <shard> <from_node> <to_node>"""
        index     = self.__argv(argv, 0)
        shard     = self.__argv(argv, 1)
        from_node = self.__argv(argv, 2)
        to_node   = self.__argv(argv, 3)
        settings = """
        {
            "commands": [
                {
                    "move": {
                        "index": "%s",
                        "shard": "%s",
                        "from_node": "%s",
                        "to_node": "%s"
                    }
                }
            ]
        }
        """ % (index, shard, from_node, to_node)
        self.__run("_cluster/reroute?pretty", method = "POST", data = settings)

    def cancel_move_shard(self, argv = []):
        """cancel-move-shard <index> <shard> <to_node>"""
        index     = self.__argv(argv, 0)
        shard     = self.__argv(argv, 1)
        to_node   = self.__argv(argv, 2)
        settings = """
        {
            "commands": [
                {
                    "cancel": {
                        "index": "%s",
                        "shard": "%s",1
                        "node": "%s"
                    }
                }
            ]
        }
        """ % (index, shard, to_node)
        self.__run("_cluster/reroute?pretty", method = "POST", data = settings)

    def move_primary_shard(self, argv = []):
        """move-primary-shard <index> <shard> <to_node>"""
        index     = self.__argv(argv, 0)
        shard     = self.__argv(argv, 1)
        to_node   = self.__argv(argv, 2)
        settings = """
        {
            "commands": [
                {
                    "allocate_empty_primary": {
                        "index": "%s",
                        "shard": "%s",1
                        "node":  "%s",
                        "accept_data_loss": False
                    }
                }
            ]
        }
        """ % (index, shard, to_node)
        self.__run("_cluster/reroute?pretty", method = "POST", data = settings)

    def random_shuffle(self, argv = []):
        """random-shuffle <index> <seed>"""
        index = self.__argv(argv, 0)
        seed  = self.__argv(argv, 1)
        size  = self.options["size"]
        settings = """
        {
            "query": {
                "function_score": {
                    "functions": [
                        {
                            "random_score": {
                                "seed": "%s"
                            }
                        }
                    ]
                }
            },
            "size": %s
        }
        """ % (seed, size)
        self.__run("%s/_search" % index,
                   data = settings, pipe = "jq -c .hits.hits[]")

    def max_result_window(self, argv = []):
        """max-result-window <index> <num>"""

    def read_mode(self, argv = []):
        """read-mode <index>"""
        index = self.__argv(argv, 0)
        self.durability([index, "request"])
        self.refresh_interval([index, "1s"])

    def write_mode(self, argv = []):
        """write-mode <index>"""
        index = self.__argv(argv, 0)
        self.durability([index, "async"])
        self.refresh_interval([index, "-1"])

    def exists(self, argv = []):
        """exists <index> <field>"""
        index = self.__argv(argv, 0)
        field = self.__argv(argv, 1)
        query = """
        {
            "query": {
                "exists": {
                    "field": "%s"
                }
            },
            "size": %s
        }""" % (field, self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    def not_exists(self, argv = []):
        """not-exists <index> <field>"""
        index = self.__argv(argv, 0)
        field = self.__argv(argv, 1)
        query = """
        {
            "query": {
              "bool": {
                "must_not": {
                  "exists": {
                    "field": "%s"
                  }
                }
              }
            },
            "size": %s
        }""" % (field, self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    def not_null(self, argv = []):
        """not-null <index> <field>"""
        index = self.__argv(argv, 0)
        field = self.__argv(argv, 1)
        query = """{
          "query": {
            "bool": {
              "must": [{
                "script": {
                  "script": {
                    "source": "doc.containsKey('%s') && doc['%s'].size() > 0"
                  }
                }
              }]
            }
          },
          "size": %s
        }""" % (field, field, self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    # Only works with keyword fields.
    def aggs(self, argv = []):
        """aggs <index> <field>"""
        index = self.__argv(argv, 0)
        field = self.__argv(argv, 1)
        query = """{
          "aggs": {
            "results": {
              "terms": {
                "field": "%s",
                "size": %s
              }
            }
          },
          "_source": false
        }""" % (field, self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    def read_only(self, argv = []):
        """read-only <index>"""
        index = self.__argv(argv, 0)
        settings = """{
          "index": {
            "blocks.write": true
          }
        }"""
        self.__run("%s/_settings?pretty" % index, method="PUT", data=settings)

    def enable_id_field_data(self, argv = []):
        """enable-id-field-data"""
        settings = '''{
            "persistent": {
                "indices.id_field_data.enabled": true
            }
        }'''
        self.__run("_cluster/settings?pretty", method="PUT", data=settings)

    def version(self, argv = []):
        """version <index>"""
        index = self.__argv(argv, 0)

        self.__run("%s/_settings?human" % index,
                   pipe="jq -r .[].settings.index.version.created_string")

    def must_match(self, argv = []):
        """must-match <index> <kv1> [<kv2>]"""

        index = self.__argv(argv, 0)
        size  = self.options["size"]

        match = []
        for i in range(1, len(argv)):
            kv = argv[i].split(":")
            if len(kv) != 2:
                raise Exception("Invalid key-value pair: %s" % argv[i])
            k, v = kv[0], kv[1]
            match.append({
                "match": {
                    k: v
                }
            })

        query = json.dumps({
            "query": {
                "bool": {
                    "must": match
                }
            }
        })
        self.__run("%s/_search?pretty&size=%s" % (index, size), "POST", data=query)

    def should_match(self, argv = []):
        """should-match <index> <kv1> [<kv2>]"""

        index = self.__argv(argv, 0)
        size  = self.options["size"]

        match = []
        for i in range(1, len(argv)):
            kv = argv[i].split(":")
            if len(kv) != 2:
                raise Exception("Invalid key-value pair: %s" % argv[i])
            k, v = kv[0], kv[1]
            match.append({
                "match": {
                    k: v
                }
            })

        query = json.dumps({
            "query": {
                "bool": {
                    "should": match
                }
            }
        })
        self.__run("%s/_search?pretty&size=%s" % (index, size), "POST", data=query)

    def filter(self, argv = []):
        """filter <index> <kv1> [<kv2>]"""

        index = self.__argv(argv, 0)
        size  = self.options["size"]

        match = []
        for i in range(1, len(argv)):
            kv = argv[i].split(":")
            if len(kv) != 2:
                raise Exception("Invalid key-value pair: %s" % argv[i])
            k, v = kv[0], kv[1]
            match.append({
                "terms": {
                    k: [v]
                }
            })

        query = json.dumps({
            "query": {
                "bool": {
                    "filter": match
                }
            }
        })
        self.__run("%s/_search?pretty&size=%s" % (index, size), "POST", data=query)

    def must_not(self, argv = []):
        """must-not <index> <kv1> [<kv2>]"""

        index = self.__argv(argv, 0)
        size  = self.options["size"]

        match = []
        for i in range(1, len(argv)):
            kv = argv[i].split(":")
            if len(kv) != 2:
                raise Exception("Invalid key-value pair: %s" % argv[i])
            k, v = kv[0], kv[1]
            match.append({
                "match": {
                    k: v
                }
            })

        query = json.dumps({
            "query": {
                "bool": {
                    "must_not": match
                }
            }
        })
        self.__run("%s/_search?pretty&size=%s" % (index, size), "POST", data=query)

    def index(self, argv = []):
        """index <index> id field_1 field_2 ... < file"""
        index = self.__argv(argv, 0)
        id = self.__argv(argv, 1, "")
        fields = self.__argvs(argv, 2)

        index_info = {
            "index": {
                "_index": index,
                #"_type": "_doc"
            }
        }

        if len(id) != 0:
            index_info["index"].update({
                "_id": id
            })

        # Convert index_info from dict to string.
        index_info = json.dumps(index_info)
        #print(index_info)

        payload = ""
        malformed = 0

        for line in sys.stdin:
            # Repalce ' with '' to make "curl -d" happy
            line = line.replace("'", "''")
            words = line.split("\n")
            # Reject the ill-format data.
            if len(words) != len(fields):
                malformed +=1

            # Fill the data.
            data = {}
            for i, field in enumerate(fields):
                data[fields[i]] = words[i]

            index_data = "%s\n%s\n" % (index_info, json.dumps(data))

            if len(index_data) + len(payload) >= self.options["max_bulk_bytes"]:
                self.__run("_bulk?pretty", "POST", data = payload)
                payload = ""

            payload += index_data

        if payload:
            self.__run("_bulk?pretty", "POST", data = payload)

    # cat 100.json | parallel 'echo {} | es post foo/_doc'
    def index_json_single(self, argv = []):
        """index-json-single <index> < json-file"""

        index = self.__argv(argv, 0)
        type = "_doc"
        for line in sys.stdin:
            print(line)
            self.__run("%s/%s" % (index, type), "POST", data = line)

    # Use bulk API to index a json input.
    def index_json(self, argv = []):
        """index-json <index> [<id-field>] < json-file"""

        index = self.__argv(argv, 0, None)
        id_field = self.__argv(argv, 1, None)
        payload = ""

        id = 0
        for line in sys.stdin:
            id += 1

            data = json.loads(line)
            if id_field:
                _id = data[id_field]
            else:
                _id = data["id"] if "id" in data else str(id)
            #_type = "_doc"
            _index = index

            # Remove id from the data since we have _id.
            if "id" in data: del(data["id"])

            # Don't need to index the index field if provided.
            if "index" in data:
                # Use the index in the data if not provided from CLI.
                if not _index:
                    _index =  data["index"]
                del(data["index"])

            # Remove fields with empty list.
            for k in list(data.keys()):
                if data[k] == []:
                    del(data[k])

            index_info = {
                "index": {
                    "_index": _index,
                    #"_type": _type,
                    "_id": _id
                }
            }
            index_data = "%s\n%s\n" % (json.dumps(index_info),
                                       json.dumps(data, ensure_ascii = False))

            if len(index_data) + len(payload) >= self.options["max_bulk_bytes"]:
                try:
                    if payload:
                        self.__run("_bulk?pretty", "POST", data = payload)
                except Exception as err:
                    print(json.dumps(data))
                    print(len(index_data), len(payload))
                    print("id:", _id)
                    raise(err)

                payload = ""

            payload += index_data

        if payload:
            self.__run("_bulk?pretty", "POST", data = payload)

    # XXX: not working well when a lot of data.
    def index_dump_single(self, argv = []):
        """index-dump < dump-file"""
        for line in sys.stdin:
            data = json.loads(line)

            id = data["_id"]
            type = data["_type"]
            index = data["_index"]
            source = data["_source"]
            self.__run("%s/%s/%s" % (index, type, id),
                       method = "POST",
                       data = json.dumps(source).replace("'", ""))

    # Using bulk api to index.
    def index_dump(self, argv = []):
        """index-dump [<index>] < dump-file"""
        index = self.__argv(argv, 0, None)

        payload = ""

        for line in sys.stdin:
            data = json.loads(line)

            id = data["_id"]
            #type = data["_type"]
            index = data["_index"] if index == None else index
            source = data["_source"]

            # XXX: store_sales could be huge and caused issue.  Remove
            # it for now to make progress.
            if "store_sales" in source: del(source["store_sales"])

            index_info = {
                "index": {
                    "_index": index,
                    #"_type": type,
                    "_id": id
                }
            }
            index_data = "%s\n%s\n" % (json.dumps(index_info), json.dumps(source))

            if len(index_data) + len(payload) >= self.options["max_bulk_bytes"]:
                self.__run("_bulk?pretty", "POST", data = payload)
                payload = ""

            payload += index_data

        if payload:
            self.__run("_bulk?pretty", "POST", data = payload)

    def stemmer_override(self, argv = []):
        """stemmer-override <index> < file"""

    def synonyms(self, argv = []):
        """synonyms <index>         < file"""

    def get(self, argv = []):
        """get <index>              < file"""
        index = self.__argv(argv, 0)
        id = self.__argv(argv, 1)
        if id:
            self.__run("%s/_doc/%s?pretty" % (index, id))
        else:
            self.__run("%s/?pretty" % index, "GET", data="@-")

    def put(self, argv = []):
        """put <index>              < file"""
        index = self.__argv(argv, 0)
        self.__run("%s/?pretty" % index, "PUT", data="@-")

    def post(self, argv = []):
        """post <index>             < file"""
        index = self.__argv(argv, 0)
        self.__run("%s/?pretty" % index, "POST", data="@-")

    def search(self, argv = []):
        """search <index>           < file"""
        index   = self.__argv(argv, 0)
        f       = self.options["from"]
        size    = self.options["size"]
        human   = "true" if self.options["human"] else "false"
        rc      = "true" if self.options["request-cache"] else "false"
        explain = self.options["explain"]

        self.__run("%s/_search?pretty&from=%s&size=%s&human=%s&request_cache=%s&explain=%s" % (index, f, size, human, rc, explain), data="@-")

    def update(self, argv = []):
        """update <index> <doc_id> <field> <value>"""
        index   = self.__argv(argv, 0)
        doc_id  = self.__argv(argv, 1)
        field   = self.__argv(argv, 2)
        value   = self.__argv(argv, 3)

        # Add quotation around strings, and skip otherwise.
        if value and value[0] != "[":
            value = '"%s"' % value

        data = """{
            "doc": {
                "%s": %s
            }
        }""" % (field, value)

        self.__run("%s/_update/%s" % (index, doc_id), method="POST", data=data)

    # https://www.elastic.co/guide/en/elasticsearch/reference/8.18/docs-update-by-query.html
    def update_by_query(self, argv = []):
        """update-by-query <index> <field-key> <field-value> <key> <value> <threshold>"""
        index       = self.__argv(argv, 0)
        field_key   = self.__argv(argv, 1)
        field_value = self.__argv(argv, 2)
        key         = self.__argv(argv, 3)
        value       = self.__argv(argv, 4)
        threshold   = self.__argv(argv, 5, "-1")

        # Add quotation around strings, and skip otherwise.
        if value and value[0] != "[":
            value = '"%s"' % value

        data = """{
            "query": {
              "term": {
                "%s": "%s"
              }
            },
            "script": {
              "source": "ctx._source['%s'] = %s"
            }
        }""" % (field_key, field_value, key, value)

        self.__run("%s/_update_by_query?requests_per_second=%s" % (index, threshold), method="POST", data=data, pipe="jq")

    def suggest(self, argv = []):
        """suggest <index> <term> <field> <fuzziness> [<country1> <country2> ...]"""
        index     = self.__argv(argv, 0)
        term      = self.__argv(argv, 1)
        field     = self.__argv(argv, 2)
        fuzziness = self.__argv(argv, 3, 0)
        country   = self.__argvs(argv, 4, ["US"])
        query = '''
        {
            "suggest": {
                "autocomplete": {
                    "prefix": "%s",
                    "completion": {
                        "field": "%s",
                        "skip_duplicates": false,
                        "fuzzy": {
                          "fuzziness": "%s"
                        },
                        "contexts": {
                          "store_country": %s
                        },
                        "size": %s
                    }
                }
            }
        }
        ''' % (term, field, fuzziness, json.dumps(country), self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    def prefix_search(self, argv = []):
        """prefix-search <index> <term> <field>"""
        index   = self.__argv(argv, 0)
        term = self.__argv(argv, 1)
        field = self.__argv(argv, 2)
        query = '''
        {
            "query": {
                "match_phrase_prefix": {
                    "%s": {
                        "query": "%s",
                        "analyzer": "name_analyzer_no_dash"
                    }
                }
            },
            "from": %s,
            "size": %s
        }
        ''' % (field, term, self.options["from"], self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    # XXX
    def rank_feature(self, argv = []):
        """rank-feature <index> <field> <feature>"""
        index   = self.__argv(argv, 0)
        field   = self.__argv(argv, 1)
        feature = self.__argv(argv, 2)
        query = '''
        {
            "query": {
                "bool": {
                    "should": {
                        "rank_feature": {
                            "field": "%s.%s"
                        }
                    }
                }
            },
            "from": %s,
            "size": %s
        }
        '''% (field, feature, self.options["from"], self.options["size"])
        self.__run("%s/_search?pretty" % index, data = query)

    def ls(self, argv = []):
        """ls [<index>] [-o <index|docs|size>]]"""
        index = self.__argv(argv, 0)

        if index: index += "*"
        pipe = None if index or self.options["all"] else "grep -v '^\.'"

        sort = self.options["option"] or "index"
        if sort == "docs":
            sort = "docs.count"
        elif sort == "size":
            sort = "pri.store.size"

        fields = [
            "index",
            "health",
            "status",
            "pri",
            "rep",
            "docs.count",
            "docs.deleted",
            "store.size",
            "pri.store.size",
        ]
        if index:
            self.__run("_cat/indices/%s?v&s=%s&h=%s" % \
                       (index, sort, ",".join(fields)), pipe = pipe)
        else:
            self.__run("_cat/indices?v&s=%s&h=%s" % \
                       (sort, ",".join(fields)), pipe = pipe)

    def cat(self, argv = []):
        """cat [<index>]"""
        index = self.__argv(argv, 0)
        size  = self.options["size"]
        self.__run("%s/_search?pretty&size=%s" % (index, size))

    def rm(self, argv = []):
        """rm <index> [[<type> <id>] [<routing>]]"""
        index   = self.__argv(argv, 0)
        type    = self.__argv(argv, 1)
        id      = urllib.parse.quote_plus(self.__argv(argv, 2))
        routing = self.__argv(argv, 3)

        path = index
        if type:    path += "/%s" % type
        if id:      path += "/%s" % id
        #path += "?pretty"
        if routing: path += "&routing=%s" % routing
        self.__run(path, "DELETE")

    def grep(self, argv = []):
        """grep <term> [<index>]"""
        term = self.__argv(argv, 0)
        index   = self.__argv(argv, 1)

        # If it's nested query, use post, otherwise, use query string.
        kv = term.split(":")
        if len(kv) >= 2 and "." in kv[0]:
            field = kv[0].split(".")
            query = json.dumps({
                "query": {
                    "nested": {
                        "path": field[0],
                        "query": {
                            "match_bool_prefix": {
                                kv[0]: kv[1]
                            }
                        }
                    }
                }
            })
            self.__run("%s/_search?pretty" % index, "POST", data=query)
        else:
            term  = urllib.parse.quote_plus(term)
            index = self.__argv(argv, 1)
            size  = self.options["size"]
            self.__run("%s/_search?q=%s&pretty&size=%s" % (index, term, size))

    def delete(self, argv = []):
        """delete <index> <id> <type>"""
        index = self.__argv(argv, 0)
        id    = self.__argv(argv, 1)
        type  = self.__argv(argv, 2, "_doc")
        self.__run("%s/%s/%s" % (index, type, id), "DELETE")

    def delete_by_query(self, argv = []):
        """delete-by-query <index> <key> <value>"""
        index = self.__argv(argv, 0)
        key   = self.__argv(argv, 1)
        value = self.__argv(argv, 2)

        query = json.dumps({
            "query": {
                "match": {
                    key: value
                }
            }
        })
        self.__run("%s/_delete_by_query" % index, "POST", data=query, pipe="jq")

    def ltr_featureset(self, argv = []):
        """ltr-featureset <feature>"""
        feature = self.__argv(argv, 0)
        self.__run("_ltr/_featureset/%s?pretty" % feature)

    def create_ltr_featureset(self, argv = []):
        """create-ltr-featureset <name>"""
        name = self.__argv(argv, 0)
        self.__run("_ltr/_featureset/%s?pretty" % name, "POST", data = "@-")

    def delete_ltr_featureset(self, argv = []):
        """delete-ltr-featureset <name>"""
        name = self.__argv(argv, 0)
        self.__run("_ltr/_featureset/%s?pretty" % name, "DELETE")

    def ltr_model(self, argv = []):
        """ltr-model <name>"""
        name = self.__argv(argv, 0)
        self.__run("_ltr/_model/%s?pretty" % name)

    def create_ltr_model(self, argv = []):
        """create-ltr-model <name> <feature-set>"""
        name = self.__argv(argv, 0)
        feature_set = self.__argv(argv, 1)
        data = {
            "model": {
                "name": name,
                "model": {
                    "type": "model/xgboost+json",
                    "definition": json.load(sys.stdin),
                }
            }
        }
        self.__run("_ltr/_featureset/%s/_createmodel?pretty" % feature_set,
                   "POST", data = json.dumps(data))

    def delete_ltr_model(self, argv = []):
        """delete-ltr-model <name>"""
        name = self.__argv(argv, 0)
        self.__run("_ltr/_model/%s?pretty" % name, "DELETE")

    def api_keys(self, argv = []):
        """api-keys <name>"""
        name = self.__argv(argv, 0)
        self.__run("_security/api_key?name=%s&pretty" % name)

    def create_api_key(self, argv = []):
        """create-api-key <name> <expiration>"""
        name = self.__argv(argv, 0)
        expiration = self.__argv(argv, 1, "1d")

        req = json.dumps({
            "name": name,
            "expiration": expiration,
        })
        self.__run("_security/api_key", "POST", data=req)

    def delete_api_key(self, argv = []):
        """delete-api-key <user> <key-id>"""
        user = self.__argv(argv, 0)
        key_id = self.__argv(argv, 1)

        #self.__run("api/v1/users/%s/auth/keys/%s" % (user, key_id), "DELETE")
        req = json.dumps({
          "ids": [key_id]
        })
        self.__run("_security/api_key", "DELETE", data=req)

    def user(self, argv = []):
        """user [<user>]"""
        user = self.__argv(argv, 0)

        if user:
            self.__run("_security/user/%s?pretty" % user)
        else:
            self.__run("_security/user?pretty")

    def create_user(self, argv = []):
        """create-user <username> <password> <roles>"""
        username = self.__argv(argv, 0)
        password = self.__argv(argv, 1)
        roles    = self.__argvs(argv, 2, ["superuser"])
        settings = json.dumps({
          "password": password,
          "roles": roles
        })

        self.__run("_security/user/%s?pretty" % username,
                   method="POST", data=settings)

    def delete_user(self, argv = []):
        """delete-user <username>"""
        username = self.__argv(argv, 0)

        self.__run("_security/user/%s?pretty" % username, "DELETE")

    def create_superuser(self, argv = []):
        """create-superuser <username> <password>"""
        username = self.__argv(argv, 0)
        password = self.__argv(argv, 1)

        self.create_super_role(["superpower"])
        self.create_user([username, password, "superuser", "superpower"])

    def role(self, argv = []):
        """role [<role>]"""
        role = self.__argv(argv, 0)

        if role:
            self.__run("_security/role/%s?pretty" % role)
        else:
            self.__run("_security/role?pretty")

    def delete_role(self, argv = []):
        """delete-role [<role>]"""
        role = self.__argv(argv, 0)

        self.__run("_security/role/%s?pretty" % role, "DELETE")

    def create_super_role(self, argv = []):
        """create-super-role [<role>]"""
        role = self.__argv(argv, 0)

        settings = json.dumps({
            "indices": [{
                "names": [ "*", ".*" ],
                "privileges": [ "all" ],
                "allow_restricted_indices": True
            }]
        })
        self.__run("_security/role/%s?pretty" % role, "POST", data=settings)

    def role_mapping(self, argv = []):
        """role-mapping [<user>]"""
        user = self.__argv(argv, 0)

        if user:
            self.__run("_security/role_mapping/%s?pretty" % user)
        else:
            self.__run("_security/role_mapping?pretty")

    def create_role_mapping(self, argv = []):
        """create-role-mapping <name> <user> <role>"""
        name = self.__argv(argv, 0)
        user = self.__argv(argv, 1)
        role = self.__argv(argv, 2)

        mappings = """{
          "rules": {
            "field": { "username": "%s" }
          },
          "roles": [ "%s" ],
          "enabled": true
        }""" % (user, role)
        self.__run("_security/role_mapping/%s?pretty" % name,
                   method="POST", data=mappings)

    def delete_role_mapping(self, argv = []):
        """delete-role-mapping <name>"""
        name = self.__argv(argv, 0)

        self.__run("_security/role_mapping/%s?pretty" % name, method="DELETE")

    def privilege(self, argv = []):
        """privilege [<user>]"""
        user = self.__argv(argv, 0)

        if user:
            self.__run("_security/user/_privileges/%s?pretty" % role)
        else:
            self.__run("_security/user/_privileges?pretty")


# The main function.
if __name__ == "__main__":
    cli = argparse.ArgumentParser(description="Elasticsearch Utility.")
    cli.add_argument("-a", "--all", default=False, action="store_true",
                     help="All including hidden indices")
    cli.add_argument("-e", "--explain", default=False, action="store_true",
                     help="Explain ES query")
    cli.add_argument("-o", "--option", help="Option")
    cli.add_argument("-s", "--server", help="ES server", default="localhost")
    cli.add_argument("-p", "--port", help="ES port", default=9200)
    cli.add_argument("-u", "--username", help="Username")
    cli.add_argument("-P", "--password", help="Password")
    cli.add_argument("-v", "--verbose", help="Verbosity", action="count")
    cli.add_argument("-z", "--size", help="Size", default=30)
    cli.add_argument("-f", help="From", default=0)
    cli.add_argument("--human", default=False, action="store_true",
                     help="Display human readable output")
    cli.add_argument("-rc", "--request-cache", default=False, action="store_true",
                     help="Enable request Cache")
    cli.add_argument("command", type=str, help="Commands")
    cli.add_argument("argv", type=str, nargs="*", help="Arguments")
    args = cli.parse_args()

    options = {
        "host":           os.getenv("ES_SERVER", args.server),
        "port":           os.getenv("ES_PORT", args.port),
        "username":       os.getenv("ES_USERNAME", args.username),
        "password":       os.getenv("ES_PASSWORD", args.password),
        "verbose":        args.verbose,
        "silent":         False,
        "method":         "GET",
        "v2":             False,
        "size":           args.size,
        "from":           args.f,
        "max_bulk_bytes": 600000,
        "option":         args.option,
        "human":          args.human,
        "explain":        "true" if args.explain else "false",
        "all":            args.all,
        "request-cache":  args.request_cache,
    }

    ES(options).run(args.command, args.argv)
